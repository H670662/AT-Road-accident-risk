{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LGBM regressor\n",
    "LGM regressor scorer ofte bra, jeg har valgt å bruke denne for å se hva vi kan få ut av datasettet uten større mengde feature engineering.\n",
    "\n",
    "## importere bibloteker"
   ],
   "id": "b4ff438af74554d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "dca1603cf68a68fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T22:27:51.137074Z",
     "start_time": "2025-10-30T22:27:51.129526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from lightgbm import LGBMRegressor, early_stopping, log_evaluation\n",
    "from sklearn.impute import SimpleImputer\n"
   ],
   "id": "f0ca7c9fcd13ccc7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## for å hente ut data",
   "id": "94ca17a6691f4b92"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-30T22:27:51.460390Z",
     "start_time": "2025-10-30T22:27:51.457179Z"
    }
   },
   "source": [
    "def load_data():\n",
    "    # Read training, test, and sample submission datasets\n",
    "    train = pd.read_csv(\"input/train.csv\")\n",
    "    test = pd.read_csv(\"input/test.csv\")\n",
    "    sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "    # Return all three datasets\n",
    "    return train, test, sample_submission\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evt. feature engineering",
   "id": "c55cd82720e4d8c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T22:27:51.711547Z",
     "start_time": "2025-10-30T22:27:51.707127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_engineered_features(df):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame with raw features.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with added engineered features (non-destructive copy).\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Feature 1: speed / curvature (protect against div-by-zero with small epsilon)\n",
    "    speed_o_curve = df[\"speed_limit\"] / (df[\"curvature\"] + 1e-6)\n",
    "    df[\"speed_o_curve\"] = speed_o_curve.fillna(0)\n",
    "\n",
    "    # Feature 2 (disabled): speed squared\n",
    "    # speed_x_speed = df[\"speed_limit\"] ** 2\n",
    "    # df[\"speed_x_speed\"] = speed_x_speed.fillna(0)\n",
    "\n",
    "    # Feature 3 (disabled): speed * reported accidents\n",
    "    # speed_x_accidents = df[\"speed_limit\"] * df[\"num_reported_accidents\"]\n",
    "    # df[\"speed_x_accidents\"] = speed_x_accidents.fillna(0)\n",
    "\n",
    "    # Feature 4: visibility risk components (lighting + weather) and composite\n",
    "    lighting_w = {\"night\": 0.9, \"dim\": 0.3, \"daylight\": 0.1}\n",
    "    weather_w = {\"foggy\": 0.8, \"rainy\": 0.7, \"clear\": 0.1}\n",
    "\n",
    "    df[\"lighting_risk\"] = df[\"lighting\"].map(lighting_w).fillna(0)\n",
    "    df[\"weather_risk\"] = df[\"weather\"].map(weather_w).fillna(0)\n",
    "    df[\"visibility_composite\"] = (df[\"lighting_risk\"] + df[\"weather_risk\"]) / 2\n",
    "\n",
    "    # Feature 5: time of day as ordinal integer\n",
    "    time_order = {\"morning\": 1, \"evening\": 2, \"afternoon\": 3}\n",
    "    df[\"time_as_int\"] = df[\"time_of_day\"].map(time_order)\n",
    "\n",
    "    # # Feature 6: log1p(speed / curvature)\n",
    "    # df[\"log_speed_o_curve\"] = np.log1p(speed_o_curve)\n",
    "    #\n",
    "    # # Feature 7: curvature * speed\n",
    "    # df[\"curvature_x_speed\"] = df[\"curvature\"] * df[\"speed_limit\"]\n",
    "    #\n",
    "    # # Feature 8: reported accidents per lane (add 1 to avoid div-by-zero)\n",
    "    # df[\"accidents_o_lanes\"] = df[\"num_reported_accidents\"] / (df[\"num_lanes\"] + 1)\n",
    "    #\n",
    "    # # Feature 9: speed * time (ordinal)\n",
    "    # df[\"speed_time_interaction\"] = df[\"speed_limit\"] * df[\"time_as_int\"]\n",
    "    #\n",
    "    # # Feature 10: curvature * time (ordinal)\n",
    "    # df[\"curvature_time_interaction\"] = df[\"curvature\"] * df[\"time_as_int\"]\n",
    "\n",
    "    return df\n"
   ],
   "id": "423ebd91db598833",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## preparere features for bruk i modell",
   "id": "5cf06908492b44d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T22:27:52.065151Z",
     "start_time": "2025-10-30T22:27:52.059350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_features(train, test):\n",
    "    # Create engineered features\n",
    "    train = create_engineered_features(train)\n",
    "    test = create_engineered_features(test)\n",
    "\n",
    "    # Separate features and target variable\n",
    "    X = train.drop(columns=[\"accident_risk\", \"id\"])\n",
    "    y = train[\"accident_risk\"]\n",
    "\n",
    "\n",
    "    # Define categorical feature names\n",
    "    categorical_features = [\n",
    "        \"road_type\",\n",
    "        \"lighting\",\n",
    "        \"weather\",\n",
    "        \"time_of_day\"\n",
    "    ]\n",
    "\n",
    "    # Define numerical feature names\n",
    "    numerical_features = [\n",
    "        \"num_lanes\",                # base\n",
    "        \"curvature\",                # base\n",
    "        \"speed_limit\",              # base\n",
    "        \"num_reported_accidents\",   # base\n",
    "\n",
    "        \"speed_o_curve\",            # Feature 1\n",
    "        # \"speed_x_speed\",          # Feature 2 (disabled)\n",
    "        # \"speed_x_accidents\",      # Feature 3 (disabled)\n",
    "\n",
    "        \"visibility_composite\",     # Feature 4 (composite)\n",
    "        \"lighting_risk\",            # Feature 4 (component)\n",
    "        \"weather_risk\",             # Feature 4 (component)\n",
    "\n",
    "        \"time_as_int\",              # Feature 5\n",
    "        # \"log_speed_o_curve\",        # Feature 6\n",
    "        # \"curvature_x_speed\",        # Feature 7\n",
    "        # \"accidents_o_lanes\",        # Feature 8\n",
    "        # \"speed_time_interaction\",   # Feature 9\n",
    "        # \"curvature_time_interaction\",  # Feature 10\n",
    "    ]\n",
    "\n",
    "\n",
    "    boolean_features = [\n",
    "        \"holiday\",\n",
    "        \"school_season\",\n",
    "        \"road_signs_present\",\n",
    "        \"public_road\"\n",
    "    ]\n",
    "\n",
    "    print(f\"Features: {X.shape[1]}\")\n",
    "\n",
    "        # --- Normalize column dtypes to avoid np.isnan / pd.NA type issues ---\n",
    "    for col in categorical_features:\n",
    "        if col in X.columns:\n",
    "            X[col] = X[col].astype(\"string\").fillna(\"__MISSING__\")\n",
    "            test[col] = test[col].astype(\"string\").fillna(\"__MISSING__\")\n",
    "\n",
    "\n",
    "    for col in boolean_features:\n",
    "        X[col] = X[col].astype(\"boolean\")\n",
    "        test[col] = test[col].astype(\"boolean\")\n",
    "\n",
    "    for col in numerical_features:\n",
    "        # Coerce nullable numerics (like Int64) to float64\n",
    "        X[col] = pd.to_numeric(X[col], errors=\"coerce\")\n",
    "        test[col] = pd.to_numeric(test[col], errors=\"coerce\")\n",
    "\n",
    "    # --- Pipelines for each type ---\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True))\n",
    "    ])\n",
    "\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        # with_mean=False keeps it compatible with sparse output\n",
    "        (\"scaler\", StandardScaler(with_mean=False))\n",
    "    ])\n",
    "\n",
    "    # Combine everything in a ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            #(\"cat\", categorical_transformer, categorical_features),\n",
    "            (\"num\", numerical_transformer, numerical_features),\n",
    "            # You can include boolean features as numeric 0/1\n",
    "            (\"bool\", \"passthrough\", boolean_features)\n",
    "        ],\n",
    "        sparse_threshold=0.3\n",
    "    )\n",
    "\n",
    "    # Return features, target, test set, and preprocessor\n",
    "    return X, y, test, preprocessor"
   ],
   "id": "82855141887adfde",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## bygge en stacked model",
   "id": "aaa9b8ca4b50e0be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T22:27:52.293318Z",
     "start_time": "2025-10-30T22:27:52.290061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_lgbm_model(preprocessor):\n",
    "    # LightGBM best hyperparameters\n",
    "    params = {\n",
    "        \"n_estimators\": 1542,\n",
    "        \"learning_rate\": 0.004624613524705627,\n",
    "        \"max_depth\": 12,\n",
    "        \"num_leaves\": 258,\n",
    "        \"subsample\": 0.6963927503033583,\n",
    "        \"colsample_bytree\": 0.9755243540395523,\n",
    "        \"reg_lambda\": 0.0034553945666010275,\n",
    "        \"reg_alpha\": 0.12863137655092372,\n",
    "        \"min_child_samples\": 8,\n",
    "        \"subsample_freq\": 1\n",
    "    }\n",
    "\n",
    "    # Create pipeline with preprocessing and LightGBM\n",
    "    model = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"regressor\", LGBMRegressor(\n",
    "            **params,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbosity=-1\n",
    "        ))\n",
    "    ])\n",
    "    return model"
   ],
   "id": "fbdbec6280b66678",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# STacked bodel lgbm, rf, enet",
   "id": "734ab36dd8840d66"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T00:06:33.082037Z",
     "start_time": "2025-10-31T00:06:33.071393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import RidgeCV, ElasticNet\n",
    "from sklearn.ensemble import StackingRegressor, RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import numpy as np\n",
    "\n",
    "# --- Helpers ---\n",
    "def get_lgbm_best():\n",
    "    return LGBMRegressor(\n",
    "        n_estimators=1542,\n",
    "        learning_rate=0.004624613524705627,\n",
    "        max_depth=12,\n",
    "        num_leaves=258,\n",
    "        subsample=0.6963927503033583,\n",
    "        colsample_bytree=0.9755243540395523,\n",
    "        reg_lambda=0.0034553945666010275,\n",
    "        reg_alpha=0.12863137655092372,\n",
    "        min_child_samples=8,\n",
    "        subsample_freq=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=-1\n",
    "    )\n",
    "\n",
    "def build_lgbm_model(preprocessor):\n",
    "    print(\"Building LightGBM model...\")\n",
    "    return Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"regressor\", get_lgbm_best())\n",
    "    ])\n",
    "\n",
    "def build_stacked_model(preprocessor):\n",
    "    print(\"Building Stacked model...\")\n",
    "    lgbm = get_lgbm_best()\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=200,        # cut trees\n",
    "        max_depth=16,            # cap depth\n",
    "        min_samples_leaf=5,      # fewer leaves\n",
    "        max_features=\"sqrt\",\n",
    "        n_jobs=1,                # <<< 1\n",
    "        random_state=42\n",
    "    )\n",
    "    print(\"Building Stacked model...\")\n",
    "    enet = ElasticNet(alpha=0.0005, l1_ratio=0.1, max_iter=2000, random_state=42)\n",
    "\n",
    "    print(\"Building Stacked model...\")\n",
    "    stack = StackingRegressor(\n",
    "        estimators=[(\"lgbm\", lgbm), (\"rf\", rf), (\"enet\", enet)],\n",
    "        final_estimator=RidgeCV(alphas=np.logspace(-4, 4, 25)),\n",
    "        cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        passthrough=False,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    return Pipeline(steps=[(\"preprocessor\", preprocessor), (\"stack\", stack)])\n",
    "\n",
    "def evaluate_cv(model, X, y, scoring=\"neg_root_mean_squared_error\"):\n",
    "    print(\"Evaluating CV...\")\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    mean, std = np.mean(scores), np.std(scores)\n",
    "    return mean, std, scores  # note: for neg metrics, higher is better\n"
   ],
   "id": "da6e621db412c107",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## skape submission fil",
   "id": "e293c8602154fb3a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T00:06:33.415036Z",
     "start_time": "2025-10-31T00:06:33.410618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "def generate_submission(model, X, y, test, sample_submission, path=\"submissions/finalmodel2.csv\"):\n",
    "    # Fit end-to-end pipeline and predict\n",
    "    model.fit(X, y)\n",
    "    preds = model.predict(test)\n",
    "\n",
    "    # Prepare submission\n",
    "    submission = sample_submission.copy()\n",
    "    submission[\"accident_risk\"] = preds\n",
    "\n",
    "    # Ensure folder exists\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    submission.to_csv(path, index=False)\n",
    "    print(f\"Submission saved to {path}\")\n"
   ],
   "id": "f28a3d1f060428a2",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T00:06:33.714941Z",
     "start_time": "2025-10-31T00:06:33.709072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    # Load datasets\n",
    "    train, test, sample_submission = load_data()\n",
    "\n",
    "    # Prepare features and preprocessing\n",
    "    X, y, test, preprocessor = prepare_features(train, test)\n",
    "\n",
    "    # Build candidate models\n",
    "    # lgbm_model = build_lgbm_model(preprocessor)\n",
    "    stacked_model = build_stacked_model(preprocessor)\n",
    "\n",
    "    # CV comparison (change scoring to your metric if needed)\n",
    "    # lgbm_mean, lgbm_std, _ = evaluate_cv(lgbm_model, X, y, scoring=\"neg_root_mean_squared_error\")\n",
    "    stack_mean, stack_std, _ = evaluate_cv(stacked_model, X, y, scoring=\"neg_root_mean_squared_error\")\n",
    "\n",
    "    winner = stacked_model\n",
    "\n",
    "    # print(f\"LGBM CV (neg RMSE): mean={lgbm_mean:.6f} ± {lgbm_std:.6f}\")\n",
    "    print(f\"Stack CV (neg RMSE): mean={stack_mean:.6f} ± {stack_std:.6f}\")\n",
    "\n",
    "    # Pick the winner (higher is better for neg metrics)\n",
    "    # winner = stacked_model if stack_mean > lgbm_mean else lgbm_model\n",
    "    # print(\"Selected model:\", \"Stacked\" if winner is stacked_model else \"LGBM\")\n",
    "\n",
    "    # Fit on full training data and predict test\n",
    "    winner.fit(X, y)\n",
    "    preds = winner.predict(test)\n",
    "\n",
    "    # Make submission\n",
    "    generate_submission(winner, X, y, test, sample_submission)"
   ],
   "id": "bdeefe93ec87bc41",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T00:37:58.616751Z",
     "start_time": "2025-10-31T00:06:33.870025Z"
    }
   },
   "cell_type": "code",
   "source": "main()",
   "id": "803e13be4bb52e15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 17\n",
      "Building Stacked model...\n",
      "Building Stacked model...\n",
      "Building Stacked model...\n",
      "Evaluating CV...\n",
      "Stack CV (neg RMSE): mean=-0.055984 ± 0.000114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tebje\\Documents\\HVLIT\\GithubRepos\\AT-Road-Accident-Risk\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\tebje\\Documents\\HVLIT\\GithubRepos\\AT-Road-Accident-Risk\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to submissions/finalmodel2.csv\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T10:07:56.281056Z",
     "start_time": "2025-10-29T10:07:56.279445Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7d3c7c28c52d869b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:15:05.463847Z",
     "start_time": "2025-10-28T22:40:14.854560Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "73f7370b68e00151",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:15:05.474228100Z",
     "start_time": "2025-10-28T22:40:14.863217Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "24332ec4db42523e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b0135d56e0a2339b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dd428530f7d40011"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2fc3f39679db14d5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
