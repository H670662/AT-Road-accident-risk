{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-26T14:10:54.311087Z",
     "start_time": "2025-10-26T14:10:52.538073Z"
    }
   },
   "source": [
    "# ============================================================\n",
    "# Import required libraries\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from lightgbm import LGBMRegressor, early_stopping, log_evaluation\n",
    "from xgboost import XGBRegressor"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T14:10:57.461481Z",
     "start_time": "2025-10-26T14:10:56.261523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Function: Load data from CSV files\n",
    "# ============================================================\n",
    "def load_data():\n",
    "    # Read training, test, and sample submission datasets\n",
    "    train = pd.read_csv(\"input/train.csv\")\n",
    "    test = pd.read_csv(\"input/test.csv\")\n",
    "    sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "    # Return all three datasets\n",
    "    return train, test, sample_submission\n",
    "\n",
    "load_data()\n",
    "train, test, smaple = load_data()\n",
    "print(train.head())"
   ],
   "id": "cae40889ddb402be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id road_type  num_lanes  curvature  speed_limit  lighting weather  \\\n",
      "0   0     urban          2       0.06           35  daylight   rainy   \n",
      "1   1     urban          4       0.99           35  daylight   clear   \n",
      "2   2     rural          4       0.63           70       dim   clear   \n",
      "3   3   highway          4       0.07           35       dim   rainy   \n",
      "4   4     rural          1       0.58           60  daylight   foggy   \n",
      "\n",
      "   road_signs_present  public_road time_of_day  holiday  school_season  \\\n",
      "0               False         True   afternoon    False           True   \n",
      "1                True        False     evening     True           True   \n",
      "2               False         True     morning     True          False   \n",
      "3                True         True     morning    False          False   \n",
      "4               False        False     evening     True          False   \n",
      "\n",
      "   num_reported_accidents  accident_risk  \n",
      "0                       1           0.13  \n",
      "1                       0           0.35  \n",
      "2                       2           0.30  \n",
      "3                       1           0.21  \n",
      "4                       1           0.56  \n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T14:10:59.815300Z",
     "start_time": "2025-10-26T14:10:59.810234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Function: Create engineered features\n",
    "# ============================================================\n",
    "def create_engineered_features(df):\n",
    "    \"\"\"\n",
    "    Create 2 powerful engineered features for accident risk prediction\n",
    "\n",
    "    Parameters:\n",
    "    df: DataFrame with raw features\n",
    "\n",
    "    Returns:\n",
    "    DataFrame with added engineered features\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Feature 1: Risk Density Score\n",
    "    # Combines accident history with road capacity\n",
    "    # Higher values indicate more accidents per lane (higher risk concentration)\n",
    "    df['risk_density'] = df['num_reported_accidents'] / (df['num_lanes'] + 1)\n",
    "\n",
    "    # Feature 2: Dangerous Conditions Index\n",
    "    # Interaction between environmental/temporal risk factors\n",
    "    # Creates binary flags for high-risk conditions and combines them\n",
    "\n",
    "    # High-risk weather conditions (excluding clear/sunny)\n",
    "    weather_risk = (~df['weather'].isin(['clear', 'sunny'])).astype(int)\n",
    "\n",
    "    # Poor lighting conditions\n",
    "    lighting_risk = (df['lighting'].isin(['dark', 'dusk'])).astype(int)\n",
    "\n",
    "    # High-risk time periods (rush hours and night)\n",
    "    time_risk = (df['time_of_day'].isin(['evening', 'night', 'morning'])).astype(int)\n",
    "\n",
    "    # Dangerous road characteristics\n",
    "    road_risk = (\n",
    "        (df['curvature'] > df['curvature'].median()).astype(int) +\n",
    "        (df['speed_limit'] > df['speed_limit'].median()).astype(int)\n",
    "    )\n",
    "\n",
    "    # Combine all risk factors into composite score\n",
    "    df['dangerous_conditions_index'] = (\n",
    "        weather_risk * 2 +  # Weather weighted heavily\n",
    "        lighting_risk * 1.5 +  # Lighting is important\n",
    "        time_risk * 1.2 +  # Time of day matters\n",
    "        road_risk * 0.8  # Road characteristics\n",
    "    )\n",
    "\n",
    "    return df"
   ],
   "id": "414d02dc8ee93fe9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T20:54:16.756345Z",
     "start_time": "2025-10-05T20:54:16.751926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Function: Prepare features for model training\n",
    "# ============================================================\n",
    "def prepare_features(train, test):\n",
    "    # Create engineered features\n",
    "    train = create_engineered_features(train)\n",
    "    test = create_engineered_features(test)\n",
    "\n",
    "    # Separate features and target variable\n",
    "    X = train.drop(columns=[\"accident_risk\"])\n",
    "    y = train[\"accident_risk\"]\n",
    "\n",
    "    # Define categorical feature names\n",
    "    categorical_features = [\n",
    "        \"road_type\",\n",
    "        \"lighting\",\n",
    "        \"weather\",\n",
    "        \"time_of_day\"\n",
    "    ]\n",
    "\n",
    "    # Define numerical feature names\n",
    "    numerical_features = [\n",
    "        \"num_lanes\",\n",
    "        \"curvature\",\n",
    "        \"speed_limit\",\n",
    "        \"num_reported_accidents\",\n",
    "        \"holiday\",\n",
    "        \"school_season\",\n",
    "        \"road_signs_present\",\n",
    "        \"public_road\",\n",
    "        \"risk_density\",\n",
    "        \"dangerous_conditions_index\"\n",
    "    ]\n",
    "\n",
    "    # One-hot encode categorical features\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "    # Standardize numerical features\n",
    "    numerical_transformer = StandardScaler()\n",
    "\n",
    "    # Combine transformations into a preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", categorical_transformer, categorical_features),\n",
    "            (\"num\", numerical_transformer, numerical_features)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Return features, target, test set, and preprocessor\n",
    "    return X, y, test, preprocessor"
   ],
   "id": "882b2a5d9c527deb",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T20:54:16.766431Z",
     "start_time": "2025-10-05T20:54:16.762442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Function: Build LightGBM model\n",
    "# ============================================================\n",
    "def build_lgbm_model(preprocessor):\n",
    "    # LightGBM hyperparameters\n",
    "    params = {\n",
    "        \"n_estimators\": 525,\n",
    "        \"learning_rate\": 0.06,\n",
    "        \"max_depth\": 8,\n",
    "        \"num_leaves\": 64,\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.9,\n",
    "        \"reg_lambda\": 0.6,\n",
    "        \"reg_alpha\": 0.2\n",
    "    }\n",
    "\n",
    "    # Create pipeline with preprocessing and LightGBM\n",
    "    model = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"regressor\", LGBMRegressor(\n",
    "            **params,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbosity=-1\n",
    "        ))\n",
    "    ])\n",
    "    return model"
   ],
   "id": "139fdebaebf457a3",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T20:54:16.965901Z",
     "start_time": "2025-10-05T20:54:16.962356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Function: Build XGBoost model\n",
    "# ============================================================\n",
    "def build_xgb_model(preprocessor):\n",
    "    # XGBoost hyperparameters\n",
    "    params = {\n",
    "        \"n_estimators\": 525,\n",
    "        \"learning_rate\": 0.06,\n",
    "        \"max_depth\": 8,\n",
    "        \"subsample\": 0.6,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "        \"reg_lambda\": 0.6,\n",
    "        \"reg_alpha\": 0.2,\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "\n",
    "    # Create pipeline with preprocessing and XGBoost\n",
    "    model = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"regressor\", XGBRegressor(\n",
    "            **params,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "    return model"
   ],
   "id": "627fedb7ce7ac92",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T20:54:17.295800Z",
     "start_time": "2025-10-05T20:54:17.290585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Function: Train models and create averaged submission\n",
    "# ============================================================\n",
    "def generate_submission(lgbm_model, xgb_model, X, y, test, sample_submission):\n",
    "    # Preprocess features\n",
    "    X_processed = lgbm_model.named_steps[\"preprocessor\"].fit_transform(X)\n",
    "    test_processed = lgbm_model.named_steps[\"preprocessor\"].transform(test)\n",
    "\n",
    "    # Train LightGBM\n",
    "    lgbm_model.named_steps[\"regressor\"].fit(\n",
    "        X_processed,\n",
    "        y,\n",
    "        eval_set=[(X_processed, y)],\n",
    "        eval_metric=\"rmse\",\n",
    "        callbacks=[\n",
    "            early_stopping(stopping_rounds=50),\n",
    "            log_evaluation(period=50)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Train XGBoost\n",
    "    xgb_model.named_steps[\"preprocessor\"].fit(X, y)\n",
    "    xgb_model.named_steps[\"regressor\"].fit(\n",
    "        xgb_model.named_steps[\"preprocessor\"].transform(X),\n",
    "        y,\n",
    "        eval_set=[(xgb_model.named_steps[\"preprocessor\"].transform(X), y)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Generate predictions from both models\n",
    "    preds_lgbm = lgbm_model.named_steps[\"regressor\"].predict(test_processed)\n",
    "    preds_xgb = xgb_model.predict(test)\n",
    "\n",
    "    # Average predictions\n",
    "    final_predictions = (preds_lgbm + preds_xgb) / 2\n",
    "\n",
    "    # Prepare submission file\n",
    "    submission = sample_submission.copy()\n",
    "    submission[\"accident_risk\"] = final_predictions\n",
    "\n",
    "    # Save CSV for Kaggle submission\n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "    # Print confirmation\n",
    "    print(\"Submission file saved as submission.csv (LGBM + XGBoost averaged)\")"
   ],
   "id": "83faa5081178e8be",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Main function: Complete execution flow\n",
    "# ============================================================\n",
    "def main():\n",
    "    # Load datasets\n",
    "    train, test, sample_submission = load_data()\n",
    "\n",
    "    # Prepare features and preprocessing\n",
    "    X, y, test, preprocessor = prepare_features(train, test)\n",
    "\n",
    "    # Build both models\n",
    "    lgbm_model = build_lgbm_model(preprocessor)\n",
    "    xgb_model = build_xgb_model(preprocessor)\n",
    "\n",
    "    # Generate final averaged submission\n",
    "    generate_submission(lgbm_model, xgb_model, X, y, test, sample_submission)"
   ],
   "id": "f61be0b0d47c8025",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-05T20:54:44.248278Z",
     "start_time": "2025-10-05T20:54:17.972049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Script entry point\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "a58786e2ddf6e019",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.0569097\ttraining's l2: 0.00323871\n",
      "[100]\ttraining's rmse: 0.0560022\ttraining's l2: 0.00313625\n",
      "[150]\ttraining's rmse: 0.0558697\ttraining's l2: 0.00312143\n",
      "[200]\ttraining's rmse: 0.0557887\ttraining's l2: 0.00311237\n",
      "[250]\ttraining's rmse: 0.055706\ttraining's l2: 0.00310315\n",
      "[300]\ttraining's rmse: 0.0556386\ttraining's l2: 0.00309565\n",
      "[350]\ttraining's rmse: 0.0555763\ttraining's l2: 0.00308873\n",
      "[400]\ttraining's rmse: 0.0555212\ttraining's l2: 0.0030826\n",
      "[450]\ttraining's rmse: 0.0554675\ttraining's l2: 0.00307664\n",
      "[500]\ttraining's rmse: 0.0554228\ttraining's l2: 0.00307169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tebje\\Documents\\HVLIT\\GithubRepos\\AT-Road-Accident-Risk\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved as submission.csv (LGBM + XGBoost averaged)\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "baf69dc3b34f75db"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
