{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LGBM regressor\n",
    "LGM regressor scorer ofte bra, jeg har valgt å bruke denne for å se hva vi kan få ut av datasettet uten større mengde feature engineering.\n",
    "\n",
    "## importere bibloteker"
   ],
   "id": "b4ff438af74554d3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "dca1603cf68a68fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T22:11:40.487541Z",
     "start_time": "2025-10-28T22:11:40.468428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from lightgbm import LGBMRegressor, early_stopping, log_evaluation\n",
    "from sklearn.impute import SimpleImputer\n"
   ],
   "id": "f0ca7c9fcd13ccc7",
   "outputs": [],
   "execution_count": 200
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## for å hente ut data",
   "id": "94ca17a6691f4b92"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-28T22:11:40.836012Z",
     "start_time": "2025-10-28T22:11:40.828441Z"
    }
   },
   "source": [
    "def load_data():\n",
    "    # Read training, test, and sample submission datasets\n",
    "    train = pd.read_csv(\"input/train.csv\")\n",
    "    test = pd.read_csv(\"input/test.csv\")\n",
    "    sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "    # Return all three datasets\n",
    "    return train, test, sample_submission\n"
   ],
   "outputs": [],
   "execution_count": 201
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evt. feature engineering",
   "id": "c55cd82720e4d8c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T23:14:02.673235Z",
     "start_time": "2025-10-28T23:14:02.659817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_engineered_features(df):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame with raw features.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with added engineered features (non-destructive copy).\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Feature 1: speed / curvature (protect against div-by-zero with small epsilon)\n",
    "    speed_o_curve = df[\"speed_limit\"] / (df[\"curvature\"] + 1e-6)\n",
    "    df[\"speed_o_curve\"] = speed_o_curve.fillna(0)\n",
    "\n",
    "    # Feature 2 (disabled): speed squared\n",
    "    # speed_x_speed = df[\"speed_limit\"] ** 2\n",
    "    # df[\"speed_x_speed\"] = speed_x_speed.fillna(0)\n",
    "\n",
    "    # Feature 3 (disabled): speed * reported accidents\n",
    "    # speed_x_accidents = df[\"speed_limit\"] * df[\"num_reported_accidents\"]\n",
    "    # df[\"speed_x_accidents\"] = speed_x_accidents.fillna(0)\n",
    "\n",
    "    # Feature 4: visibility risk components (lighting + weather) and composite\n",
    "    lighting_w = {\"night\": 0.9, \"dim\": 0.3, \"daylight\": 0.1}\n",
    "    weather_w = {\"foggy\": 0.8, \"rainy\": 0.7, \"clear\": 0.1}\n",
    "\n",
    "    df[\"lighting_risk\"] = df[\"lighting\"].map(lighting_w).fillna(0)\n",
    "    df[\"weather_risk\"] = df[\"weather\"].map(weather_w).fillna(0)\n",
    "    df[\"visibility_composite\"] = (df[\"lighting_risk\"] + df[\"weather_risk\"]) / 2\n",
    "\n",
    "    # Feature 5: time of day as ordinal integer\n",
    "    time_order = {\"morning\": 1, \"evening\": 2, \"afternoon\": 3}\n",
    "    df[\"time_as_int\"] = df[\"time_of_day\"].map(time_order)\n",
    "\n",
    "    # Feature 6: log1p(speed / curvature)\n",
    "    df[\"log_speed_o_curve\"] = np.log1p(speed_o_curve)\n",
    "\n",
    "    # Feature 7: curvature * speed\n",
    "    df[\"curvature_x_speed\"] = df[\"curvature\"] * df[\"speed_limit\"]\n",
    "\n",
    "    # Feature 8: reported accidents per lane (add 1 to avoid div-by-zero)\n",
    "    df[\"accidents_o_lanes\"] = df[\"num_reported_accidents\"] / (df[\"num_lanes\"] + 1)\n",
    "\n",
    "    # Feature 9: speed * time (ordinal)\n",
    "    df[\"speed_time_interaction\"] = df[\"speed_limit\"] * df[\"time_as_int\"]\n",
    "\n",
    "    # Feature 10: curvature * time (ordinal)\n",
    "    df[\"curvature_time_interaction\"] = df[\"curvature\"] * df[\"time_as_int\"]\n",
    "\n",
    "    return df\n"
   ],
   "id": "423ebd91db598833",
   "outputs": [],
   "execution_count": 344
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## preparere features for bruk i modell",
   "id": "5cf06908492b44d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T23:14:03.050974Z",
     "start_time": "2025-10-28T23:14:03.023369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_features(train, test):\n",
    "    # Create engineered features\n",
    "    train = create_engineered_features(train)\n",
    "    test = create_engineered_features(test)\n",
    "\n",
    "    # Separate features and target variable\n",
    "    X = train.drop(columns=[\"accident_risk\", \"id\"])\n",
    "    y = train[\"accident_risk\"]\n",
    "\n",
    "    print(f\"Features: {X.shape[1]}\")\n",
    "    # Define categorical feature names\n",
    "    categorical_features = [\n",
    "        \"road_type\",\n",
    "        \"lighting\",\n",
    "        \"weather\",\n",
    "        \"time_of_day\"\n",
    "    ]\n",
    "\n",
    "    # Define numerical feature names\n",
    "    numerical_features = [\n",
    "        \"num_lanes\",                # base\n",
    "        \"curvature\",                # base\n",
    "        \"speed_limit\",              # base\n",
    "        \"num_reported_accidents\",   # base\n",
    "\n",
    "        \"speed_o_curve\",            # Feature 1\n",
    "        # \"speed_x_speed\",          # Feature 2 (disabled)\n",
    "        # \"speed_x_accidents\",      # Feature 3 (disabled)\n",
    "\n",
    "        \"visibility_composite\",     # Feature 4 (composite)\n",
    "        \"lighting_risk\",            # Feature 4 (component)\n",
    "        \"weather_risk\",             # Feature 4 (component)\n",
    "\n",
    "        \"time_as_int\",              # Feature 5\n",
    "        \"log_speed_o_curve\",        # Feature 6\n",
    "        \"curvature_x_speed\",        # Feature 7\n",
    "        \"accidents_o_lanes\",        # Feature 8\n",
    "        \"speed_time_interaction\",   # Feature 9\n",
    "        \"curvature_time_interaction\",  # Feature 10\n",
    "    ]\n",
    "\n",
    "\n",
    "    boolean_features = [\n",
    "        \"holiday\",\n",
    "        \"school_season\",\n",
    "        \"road_signs_present\",\n",
    "        \"public_road\"\n",
    "    ]\n",
    "\n",
    "        # --- Normalize column dtypes to avoid np.isnan / pd.NA type issues ---\n",
    "    for col in categorical_features:\n",
    "        X[col] = X[col].astype(\"string\").fillna(\"__MISSING__\")\n",
    "        test[col] = test[col].astype(\"string\").fillna(\"__MISSING__\")\n",
    "\n",
    "    for col in boolean_features:\n",
    "        X[col] = X[col].astype(\"boolean\")\n",
    "        test[col] = test[col].astype(\"boolean\")\n",
    "\n",
    "    for col in numerical_features:\n",
    "        # Coerce nullable numerics (like Int64) to float64\n",
    "        X[col] = pd.to_numeric(X[col], errors=\"coerce\")\n",
    "        test[col] = pd.to_numeric(test[col], errors=\"coerce\")\n",
    "\n",
    "    # --- Pipelines for each type ---\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True))\n",
    "    ])\n",
    "\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        # with_mean=False keeps it compatible with sparse output\n",
    "        (\"scaler\", StandardScaler(with_mean=False))\n",
    "    ])\n",
    "\n",
    "    # Combine everything in a ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", categorical_transformer, categorical_features),\n",
    "            (\"num\", numerical_transformer, numerical_features),\n",
    "            # You can include boolean features as numeric 0/1\n",
    "            (\"bool\", \"passthrough\", boolean_features)\n",
    "        ],\n",
    "        sparse_threshold=0.3\n",
    "    )\n",
    "\n",
    "    # Return features, target, test set, and preprocessor\n",
    "    return X, y, test, preprocessor"
   ],
   "id": "82855141887adfde",
   "outputs": [],
   "execution_count": 345
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## bygge en modell (LGBM regressor i dette eksempelet",
   "id": "aaa9b8ca4b50e0be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T23:14:03.365028Z",
     "start_time": "2025-10-28T23:14:03.356589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Function: Build LightGBM model\n",
    "# ============================================================\n",
    "def build_lgbm_model(preprocessor):\n",
    "    # LightGBM hyperparameters\n",
    "    params = {\n",
    "        \"n_estimators\": 525,\n",
    "        \"learning_rate\": 0.06,\n",
    "        \"max_depth\": 8,\n",
    "        \"num_leaves\": 64,\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.9,\n",
    "        \"reg_lambda\": 0.6,\n",
    "        \"reg_alpha\": 0.2\n",
    "    }\n",
    "\n",
    "    # Create pipeline with preprocessing and LightGBM\n",
    "    model = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"regressor\", LGBMRegressor(\n",
    "            **params,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbosity=-1\n",
    "        ))\n",
    "    ])\n",
    "    return model"
   ],
   "id": "fbdbec6280b66678",
   "outputs": [],
   "execution_count": 346
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## skape submission fil",
   "id": "e293c8602154fb3a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T23:14:52.809257Z",
     "start_time": "2025-10-28T23:14:52.793265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Function: Train models and create averaged submission\n",
    "# ============================================================\n",
    "def generate_submission(lgbm_model, xgb_model, X, y, test, sample_submission):\n",
    "    # Preprocess features\n",
    "    X_processed = lgbm_model.named_steps[\"preprocessor\"].fit_transform(X)\n",
    "    test_processed = lgbm_model.named_steps[\"preprocessor\"].transform(test)\n",
    "\n",
    "    # Train LightGBM\n",
    "    lgbm_model.named_steps[\"regressor\"].fit(\n",
    "        X_processed,\n",
    "        y,\n",
    "        eval_set=[(X_processed, y)],\n",
    "        eval_metric=\"rmse\",\n",
    "        callbacks=[\n",
    "            early_stopping(stopping_rounds=50),\n",
    "            log_evaluation(period=50)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    # Generate predictions from both models\n",
    "    preds_lgbm = lgbm_model.named_steps[\"regressor\"].predict(test_processed)\n",
    "\n",
    "\n",
    "    # Prepare submission file\n",
    "    submission = sample_submission.copy()\n",
    "    # submission[\"accident_risk\"] = final_predictions\n",
    "    submission[\"accident_risk\"] = preds_lgbm\n",
    "\n",
    "    # Save CSV for Kaggle submission\n",
    "    submission.to_csv(\"submissions/22_engineered_features_basic_lgbm.csv\", index=False)\n",
    "\n",
    "\n",
    "    print(\"Submission file saved in submissions folder.\")"
   ],
   "id": "f28a3d1f060428a2",
   "outputs": [],
   "execution_count": 350
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T23:14:53.092440Z",
     "start_time": "2025-10-28T23:14:53.087638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    # Load datasets\n",
    "    train, test, sample_submission = load_data()\n",
    "\n",
    "    # Prepare features and preprocessing\n",
    "    X, y, test, preprocessor = prepare_features(train, test)\n",
    "\n",
    "    # Build both models\n",
    "    lgbm_model = build_lgbm_model(preprocessor)\n",
    "    #xgb_model = build_xgb_model(preprocessor)\n",
    "\n",
    "    # Generate final averaged submission\n",
    "    generate_submission(lgbm_model, _, X, y, test, sample_submission)"
   ],
   "id": "bdeefe93ec87bc41",
   "outputs": [],
   "execution_count": 351
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T23:15:03.819779Z",
     "start_time": "2025-10-28T23:14:53.928073Z"
    }
   },
   "cell_type": "code",
   "source": "main()",
   "id": "803e13be4bb52e15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 22\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's rmse: 0.0569068\ttraining's l2: 0.00323838\n",
      "[100]\ttraining's rmse: 0.0559971\ttraining's l2: 0.00313568\n",
      "[150]\ttraining's rmse: 0.0558546\ttraining's l2: 0.00311973\n",
      "[200]\ttraining's rmse: 0.0557457\ttraining's l2: 0.00310759\n",
      "[250]\ttraining's rmse: 0.0556473\ttraining's l2: 0.00309662\n",
      "[300]\ttraining's rmse: 0.0555626\ttraining's l2: 0.00308721\n",
      "[350]\ttraining's rmse: 0.0554857\ttraining's l2: 0.00307866\n",
      "[400]\ttraining's rmse: 0.0554078\ttraining's l2: 0.00307002\n",
      "[450]\ttraining's rmse: 0.0553369\ttraining's l2: 0.00306218\n",
      "[500]\ttraining's rmse: 0.0552726\ttraining's l2: 0.00305506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tebje\\Documents\\HVLIT\\GithubRepos\\AT-Road-Accident-Risk\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved in submissions folder.\n"
     ]
    }
   ],
   "execution_count": 352
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T22:42:33.933883Z",
     "start_time": "2025-10-28T22:42:33.931872Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7d3c7c28c52d869b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T22:40:14.856541Z",
     "start_time": "2025-10-28T22:40:14.854560Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "73f7370b68e00151",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T22:40:14.865175Z",
     "start_time": "2025-10-28T22:40:14.863217Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "24332ec4db42523e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b0135d56e0a2339b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
